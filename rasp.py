import asyncio
import cv2
import face_recognition
import serial
import threading
import time
import numpy as np
from bleak import BleakScanner

# ================= é…ç½®å‚æ•° =================
SERIAL_PORT = '/dev/ttyACM0'  # æ£€æŸ¥ä½ çš„ç«¯å£ ls /dev/tty*
BAUD_RATE = 115200
TAG_NAME = "FollowMe_Tag"

# æ‰«æä¸è¿åŠ¨
SCAN_DURATION = 12.0     # æ—‹è½¬ä¸€åœˆè€—æ—¶ (ç§’)
SCAN_SPEED_PWM = 300     # æ—‹è½¬æ—¶çš„ç”µæœºé€Ÿåº¦
FOLLOW_SPEED_PWM = 500   # è·Ÿéšé€Ÿåº¦
RSSI_THRESHOLD = -80     # å¯åŠ¨æ‰«æçš„ä¿¡å·é˜ˆå€¼
SAFE_DISTANCE = 30.0     # é¿éšœè·ç¦» (cm)

# PID å‚æ•° (è§†è§‰è½¬å‘)
Kp = 0.4

# ================= å…¨å±€çŠ¶æ€å˜é‡ =================
system_state = {
    "rssi": -100,           # å½“å‰è“ç‰™ä¿¡å·å¼ºåº¦
    "distance": 999.0,      # å½“å‰è¶…å£°æ³¢è·ç¦»
    "mode": "WAITING",      # æ¨¡å¼: WAITING, SCANNING, LOCKED
    "running": True
}

# ================= 1. è“ç‰™æ‰«æ (å¼‚æ­¥çº¿ç¨‹) =================
async def ble_scanner():
    """ æŒç»­æ‰«æç‰¹å®šåç§°çš„è“ç‰™è®¾å¤‡ """
    print("ğŸ”µ BLE Scanner Started...")
    def callback(device, advertisement_data):
        if device.name == TAG_NAME:
            system_state["rssi"] = device.rssi
            # è°ƒè¯•ç”¨: print(f"BLE Signal: {device.rssi}")

    scanner = BleakScanner(detection_callback=callback)
    await scanner.start()
    while system_state["running"]:
        await asyncio.sleep(1)
    await scanner.stop()

def start_ble_thread():
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(ble_scanner())

# ================= 2. STM32 é€šä¿¡ (ä¸²å£çº¿ç¨‹) =================
class STM32Interface:
    def __init__(self):
        try:
            self.ser = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=0.5)
            print("âœ… STM32 Connected.")
        except:
            print("âš ï¸ STM32 Not Found! (Running in Sim Mode)")
            self.ser = None

    def update_loop(self):
        while system_state["running"]:
            if self.ser and self.ser.in_waiting:
                try:
                    line = self.ser.readline().decode('utf-8', errors='ignore').strip()
                    if "Distance" in line:
                        # æ ¼å¼ "Distance: 25.4"
                        dist = float(line.split(':')[1].strip())
                        system_state["distance"] = dist
                except: pass
            time.sleep(0.02)

    def move(self, left, right):
        if self.ser:
            cmd = f"L:{int(left)},R:{int(right)}\n"
            self.ser.write(cmd.encode())

# ================= 3. é›·è¾¾è®¤ä¸»ç®—æ³• =================
class RadarSystem:
    def __init__(self):
        self.rssi_log = []   # (time, rssi)
        self.visual_log = [] # (time, image_roi)
        self.start_time = 0

    def start(self):
        self.rssi_log = []
        self.visual_log = []
        self.start_time = time.time()

    def record(self, frame, rssi):
        now = time.time()
        self.rssi_log.append({'t': now, 'rssi': rssi})
        
        # ä¸ºäº†ä¸å¡é¡¿ï¼Œåªå­˜ç¼©å°åçš„å›¾
        small = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)
        # å­˜æ•´å¼ å›¾ï¼Œåé¢å†åˆ‡è„¸ï¼Œé˜²æ­¢æ­¤åˆ»æ²¡æ£€æµ‹åˆ°
        self.visual_log.append({'t': now, 'img': small})

    def analyze(self):
        """ æ‰¾å‡ºä¿¡å·æœ€å¼ºæ—¶åˆ»å¯¹åº”çš„äººè„¸ç‰¹å¾ """
        print("ğŸ“Š Analyzing Scan Data...")
        if not self.rssi_log: return None

        # å¹³æ»‘ä¿¡å·
        rssi_vals = [x['rssi'] for x in self.rssi_log]
        if len(rssi_vals) < 5: return None
        smoothed = np.convolve(rssi_vals, np.ones(5)/5, mode='valid')
        
        # æ‰¾å³°å€¼
        peak_idx = np.argmax(smoothed) + 2
        peak_time = self.rssi_log[peak_idx]['t']
        peak_rssi = self.rssi_log[peak_idx]['rssi']
        print(f"ğŸ“ˆ Peak RSSI: {peak_rssi} at t={peak_time:.2f}")

        # æ‰¾å¯¹åº”æ—¶é—´çš„å›¾ç‰‡
        best_frame_data = min(self.visual_log, key=lambda x: abs(x['t'] - peak_time))
        
        # ä»è¿™å¼ å…³é”®å¸§é‡Œæå–æ­£ä¸­é—´çš„äººè„¸
        frame = best_frame_data['img']
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # æ£€æµ‹äººè„¸
        boxes = face_recognition.face_locations(rgb)
        if not boxes: 
            print("âŒ Signal Peak found, but no face visible.")
            return None
        
        # æ‰¾æœ€ä¸­é—´çš„è„¸ (ç”»é¢å®½ 160, ä¸­å¿ƒ 80)
        h, w, _ = frame.shape
        center_x = w // 2
        best_box = min(boxes, key=lambda b: abs((b[3]+b[1])/2 - center_x))
        
        # æå–ç‰¹å¾
        encoding = face_recognition.face_encodings(rgb, [best_box])[0]
        print("âœ… Master Logic Locked!")
        return encoding

# ================= 4. ä¸»é€»è¾‘ (Main Brain) =================
def main():
    # --- å¯åŠ¨çº¿ç¨‹ ---
    t_ble = threading.Thread(target=start_ble_thread, daemon=True)
    t_ble.start()

    stm32 = STM32Interface()
    t_stm = threading.Thread(target=stm32.update_loop, daemon=True)
    t_stm.start()

    # --- è§†è§‰åˆå§‹åŒ– ---
    cap = cv2.VideoCapture(0)
    cap.set(3, 640); cap.set(4, 480)
    
    radar = RadarSystem()
    master_encoding = None
    tracker = None
    
    print("ğŸ¤– Robot Online. Waiting for Signal...")

    while system_state["running"]:
        ret, frame = cap.read()
        if not ret: break
        
        # çŠ¶æ€æœºé€»è¾‘
        mode = system_state["mode"]
        current_rssi = system_state["rssi"]
        dist = system_state["distance"]

        # === çŠ¶æ€ 1: ç­‰å¾…ä¿¡å· (WAITING) ===
        if mode == "WAITING":
            stm32.move(0, 0)
            status_text = f"WAITING... RSSI: {current_rssi} dBm"
            
            if current_rssi > RSSI_THRESHOLD:
                print("ğŸš¨ Signal Detected! Starting Sweep...")
                system_state["mode"] = "SCANNING"
                radar.start()

        # === çŠ¶æ€ 2: é›·è¾¾æ‰«æ (SCANNING) ===
        elif mode == "SCANNING":
            elapsed = time.time() - radar.start_time
            status_text = f"SCANNING... {SCAN_DURATION - elapsed:.1f}s"
            
            # æœºå™¨äººè‡ªæ—‹ (å·¦è½¬)
            stm32.move(-SCAN_SPEED_PWM, SCAN_SPEED_PWM)
            
            # è®°å½•æ•°æ®
            radar.record(frame, current_rssi)

            if elapsed > SCAN_DURATION:
                stm32.move(0, 0) # åœæ­¢
                master_encoding = radar.analyze()
                
                if master_encoding is not None:
                    system_state["mode"] = "LOCKED"
                    # åˆå§‹åŒ– KCF è¿½è¸ªå™¨
                    # æ—¢ç„¶å·²ç»è®¤ä¸»ï¼Œæˆ‘ä»¬å‡è®¾ä¸»äººç°åœ¨å°±åœ¨ç”»é¢é‡Œ (è™½ç„¶å¯èƒ½ä¸åœ¨æ­£ä¸­é—´)
                    # ä¸ºäº†ç®€åŒ–ï¼ŒLOCKED çŠ¶æ€åˆæœŸå…ˆç”¨äººè„¸è¯†åˆ«æ‰¾ä¸€æ¬¡ï¼Œç„¶åæŠŠæ¡†ç»™ Tracker
                    tracker_init_needed = True 
                else:
                    print("âŒ Lock Failed. Retrying...")
                    system_state["mode"] = "WAITING"
                    # è¿™é‡Œå¯ä»¥åŠ ä¸ªé€»è¾‘ï¼šå¦‚æœå¤±è´¥ï¼Œåå‘è½¬ä¸€ç‚¹ï¼Œæˆ–è€…ä¼‘æ¯ä¸€ä¸‹

        # === çŠ¶æ€ 3: é”å®šè·Ÿéš (LOCKED) ===
        elif mode == "LOCKED":
            status_text = "LOCKED: Following Master"
            
            # é¿éšœæœ€é«˜ä¼˜å…ˆçº§
            if dist < SAFE_DISTANCE:
                stm32.move(0, 0)
                status_text = "OBSTACLE DETECTED!"
                cv2.putText(frame, "OBSTACLE", (200, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 3)
            else:
                # è§†è§‰å¤„ç†
                small_frame = cv2.resize(frame, (0,0), fx=0.25, fy=0.25)
                rgb_small = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
                
                # æ¯ä¸€å¸§éƒ½å°è¯•æ‰¾ Master çš„è„¸ (ä¸ºäº†æœ€ç¨³ï¼Œä¸ç”¨ KCF äº†ï¼ŒPi 5 è·‘ face_recognition å°å›¾åº”è¯¥æœ‰ 5-8fps)
                # å¦‚æœè¿½æ±‚é€Ÿåº¦ï¼Œå¯ä»¥åƒä¹‹å‰é‚£æ ·åŠ  KCF æ··åˆé€»è¾‘
                face_locs = face_recognition.face_locations(rgb_small)
                face_encs = face_recognition.face_encodings(rgb_small, face_locs)
                
                target_box = None
                for (top, right, bottom, left), enc in zip(face_locs, face_encs):
                    matches = face_recognition.compare_faces([master_encoding], enc, tolerance=0.5)
                    if True in matches:
                        # æ‰¾åˆ°ä¸»äºº
                        target_box = (left*4, right*4) # è¿˜åŸ X åæ ‡ç”¨äºè®¡ç®—ä¸­å¿ƒ
                        # ç”»æ¡†
                        cv2.rectangle(frame, (left*4, top*4), (right*4, bottom*4), (0, 255, 0), 2)
                        break
                
                if target_box:
                    # PID æ§åˆ¶
                    left_x, right_x = target_box
                    face_cx = (left_x + right_x) // 2
                    face_width = right_x - left_x
                    
                    error = face_cx - 320
                    turn = int(error * Kp)
                    
                    # è·ç¦»æ§åˆ¶ (åŸºäºè„¸çš„å¤§å°)
                    throttle = 0
                    if face_width < 100: # è„¸å¤ªå°(å¤ªè¿œ) -> è¿½
                        throttle = FOLLOW_SPEED_PWM
                    elif face_width > 150: # è„¸å¤ªå¤§(å¤ªè¿‘) -> åœ
                        throttle = 0
                    
                    stm32.move(throttle + turn, throttle - turn)
                else:
                    # ä¸¢å¤±ç›®æ ‡ -> åœä¸‹æˆ–åŸåœ°æœç´¢
                    stm32.move(0, 0)
                    status_text = "Master Lost..."

        # ç”»é¢æ˜¾ç¤º
        cv2.putText(frame, status_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.putText(frame, f"Dist: {dist}cm", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)
        
        cv2.imshow("Robot View", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            system_state["running"] = False
            break

    # é€€å‡ºæ¸…ç†
    stm32.move(0, 0)
    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()