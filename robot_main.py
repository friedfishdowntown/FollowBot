#!/usr/bin/env python3
"""
äººç‰©è¿½è¸ªæœºå™¨äºº - ä¸»æ§åˆ¶ç¨‹åº
ç»“åˆè“ç‰™å®šä½ã€è§†è§‰è¯†åˆ«ã€è·ç¦»ä¼ æ„Ÿå™¨çš„æ™ºèƒ½è¿½è¸ªç³»ç»Ÿ
"""

import asyncio
import time
import cv2
import numpy as np
from config import *
from STM32_Motor_Controller import STM32Controller, MotionController
from vision_tracker import VisionTracker
from BLE_scanner import BLETargetFinder

class RobotTracker:
    """ä¸»æ§åˆ¶å™¨ - çŠ¶æ€æœºå’Œå†³ç­–é€»è¾‘"""
    
    def __init__(self):
        # åˆå§‹åŒ–å„ä¸ªæ¨¡å—
        print("=" * 50)
        print("ğŸ¤– Robot Tracker Initialization")
        print("=" * 50)
        
        self.stm32 = STM32Controller()
        self.motion = MotionController(self.stm32)
        self.vision = VisionTracker()
        self.ble = BLETargetFinder()
        
        # çŠ¶æ€æœº
        self.state = STATE_INIT
        self.previous_state = None
        
        # æ§åˆ¶å˜é‡
        self.running = True
        
    async def initialize(self):
        """åˆå§‹åŒ–æµç¨‹"""
        print("\n[INIT] Starting initialization...")
        
        # 1. è¿æ¥STM32
        if not self.stm32.connect():
            print("âœ— Failed to connect STM32. Abort.")
            return False
        
        # 2. æµ‹è¯•ç”µæœº
        print("\n[INIT] Testing motors...")
        self.motion.stop()
        time.sleep(0.5)
        
        print("âœ“ Initialization complete!\n")
        return True
    
    async def state_ble_search(self):
        """çŠ¶æ€: è“ç‰™æœç´¢ç›®æ ‡"""
        print("\n" + "="*50)
        print("[BLE_SEARCH] Searching for target...")
        print("="*50)
        
        # æ‰«æè“ç‰™
        found, rssi = await self.ble.scan_for_target()
        
        if not found or rssi < RSSI_THRESHOLD_FOUND:
            print("âœ— Target not found or signal too weak. Retrying...")
            await asyncio.sleep(2)
            return STATE_BLE_SEARCH
        
        # æ‰¾åˆ°ä¿¡å·,å¼€å§‹æ—‹è½¬æ‰¾æœ€å¼ºæ–¹å‘
        await self.ble.find_strongest_direction(self.motion, num_rotations=8)
        
        return STATE_ALIGN
    
    async def state_align(self):
        """çŠ¶æ€: å¯¹å‡†ç›®æ ‡"""
        print("\n" + "="*50)
        print("[ALIGN] Aligning to target...")
        print("="*50)
        
        # å·²ç»é€šè¿‡è“ç‰™æ—‹è½¬åˆ°æœ€å¼ºæ–¹å‘äº†
        # ç°åœ¨éœ€è¦å¾®è°ƒ,è®©ç›®æ ‡è¿›å…¥ç”»é¢ä¸­å¿ƒ
        
        align_timeout = 10  # 10ç§’å¯¹å‡†è¶…æ—¶
        start_time = time.time()
        
        while time.time() - start_time < align_timeout:
            frame = self.vision.capture_frame()
            people = self.vision.detect_people(frame)
            
            if len(people) == 0:
                print("  No person in view, rotating slowly...")
                self.motion.rotate_in_place('right')
                await asyncio.sleep(0.3)
                self.motion.stop()
                continue
            
            # æ‰¾åˆ°æœ€å¤§çš„äººæ¡†
            largest = max(people, key=lambda p: p['bbox'][2] * p['bbox'][3])
            x, y, w, h = largest['bbox']
            cx = x + w // 2
            
            offset_x = cx - CAMERA_WIDTH // 2
            
            if abs(offset_x) < CENTER_DEADZONE:
                print("âœ“ Target centered!")
                self.motion.stop()
                return STATE_CAPTURE
            
            # å¾®è°ƒæ–¹å‘
            if offset_x > 0:
                print(f"  Adjusting right (offset: {offset_x}px)...")
                self.motion.rotate_in_place('right')
            else:
                print(f"  Adjusting left (offset: {offset_x}px)...")
                self.motion.rotate_in_place('left')
            
            await asyncio.sleep(0.1)
            self.motion.stop()
            await asyncio.sleep(0.2)
        
        print("âœ— Alignment timeout. Retrying BLE search...")
        return STATE_BLE_SEARCH
    
    async def state_capture(self):
        """çŠ¶æ€: æ‹æ‘„è®°å½•ç›®æ ‡ç‰¹å¾"""
        print("\n" + "="*50)
        print("[CAPTURE] Capturing target features...")
        print("="*50)
        print("âš ï¸  Please ensure target person is in front of camera!")
        await asyncio.sleep(2)
        
        success = self.vision.capture_target_features()
        
        if not success:
            print("âœ— Failed to capture target. Retrying alignment...")
            return STATE_ALIGN
        
        print("\nâœ“ Ready to track!")
        await asyncio.sleep(1)
        return STATE_TRACK
    
    async def state_track(self):
        """çŠ¶æ€: è§†è§‰è¿½è¸ª"""
        if self.previous_state != STATE_TRACK:
            print("\n" + "="*50)
            print("[TRACK] Starting visual tracking...")
            print("="*50)
        
        frame = self.vision.capture_frame()
        target = self.vision.find_target(frame)
        
        # ========== ç›®æ ‡ä¸¢å¤±å¤„ç† ==========
        if target is None:
            if self.vision.lost_frame_count > LOST_FRAME_THRESHOLD:
                print("\nâš ï¸  Target lost for too long!")
                return STATE_LOST
            else:
                # çŸ­æš‚ä¸¢å¤±,ä¿æŒæœ€åæ–¹å‘æ…¢é€Ÿå‰è¿›
                print(f"âš ï¸  Target lost ({self.vision.lost_frame_count}/{LOST_FRAME_THRESHOLD})")
                self.motion.move_with_steering(MIN_SPEED * 0.5, 0)
                return STATE_TRACK
        
        # ========== æ‰¾åˆ°ç›®æ ‡,å¼€å§‹è¿½è¸ª ==========
        cx, cy = target['center']
        bbox_area = target['area']
        
        # 1. è®¡ç®—ç”»é¢åç§»
        offset_x = cx - CAMERA_WIDTH // 2
        offset_y = cy - CAMERA_HEIGHT // 2
        
        # 2. è®¡ç®—è½¬å‘é‡ (PIDæ§åˆ¶)
        steering = self.motion.calculate_steering(offset_x)
        
        # 3. è·ç¦»èåˆä¼°ç®—
        visual_distance = self.vision.estimate_distance_from_bbox(bbox_area)
        sonar_distance = self.stm32.get_distance()
        
        # å¦‚æœåŸºæœ¬å¯¹å‡†,èåˆè¶…å£°æ³¢æ•°æ®
        if abs(offset_x) < CENTER_DEADZONE * 2:
            # ç›®æ ‡åœ¨æ­£å‰æ–¹,è¶…å£°æ³¢å¯ä¿¡
            confidence_sonar = 0.7
            confidence_visual = 0.3
        else:
            # ç›®æ ‡åç¦»,ä¸»è¦é è§†è§‰
            confidence_sonar = 0.2
            confidence_visual = 0.8
        
        fused_distance = (confidence_sonar * sonar_distance + 
                          confidence_visual * visual_distance)
        
        # 4. æ ¹æ®è·ç¦»å†³å®šé€Ÿåº¦
        if fused_distance < SAFE_DISTANCE:
            # å¤ªè¿‘,åœæ­¢
            speed = 0
            print(f"ğŸ›‘ STOP - Too close ({fused_distance:.1f}cm)")
            self.motion.stop()
            
        elif fused_distance < FOLLOW_DISTANCE:
            # ç†æƒ³è·ç¦»,æ…¢é€Ÿè·Ÿéš
            speed = MIN_SPEED
            print(f"ğŸš¶ FOLLOW - Distance: {fused_distance:.1f}cm | Steer: {steering:.2f}")
            self.motion.move_with_steering(speed, steering)
            
        elif fused_distance < MAX_DISTANCE:
            # ç¨è¿œ,ä¸­é€Ÿè¿½èµ¶
            speed = MIN_SPEED + (MAX_SPEED - MIN_SPEED) * 0.5
            print(f"ğŸƒ CHASE - Distance: {fused_distance:.1f}cm | Steer: {steering:.2f}")
            self.motion.move_with_steering(speed, steering)
            
        else:
            # å¾ˆè¿œ,å…¨é€Ÿè¿½èµ¶
            speed = MAX_SPEED
            print(f"ğŸš€ SPRINT - Distance: {fused_distance:.1f}cm | Steer: {steering:.2f}")
            self.motion.move_with_steering(speed, steering)
        
        # 5. è°ƒè¯•æ˜¾ç¤º
        if DEBUG_MODE and SAVE_DEBUG_IMAGES:
            debug_frame = self.vision.draw_debug_info(
                frame, target, offset_x, steering
            )
            cv2.imshow("Debug", debug_frame)
            cv2.waitKey(1)
        
        return STATE_TRACK
    
    async def state_lost(self):
        """çŠ¶æ€: ç›®æ ‡ä¸¢å¤±,æœç´¢æ¨¡å¼"""
        print("\n" + "="*50)
        print("[LOST] Target lost. Searching...")
        print("="*50)
        
        search_timeout = 15  # 15ç§’æœç´¢è¶…æ—¶
        start_time = time.time()
        
        while time.time() - start_time < search_timeout:
            # åŸåœ°æ—‹è½¬æœç´¢
            self.motion.rotate_in_place('right')
            await asyncio.sleep(0.5)
            self.motion.stop()
            
            # æ£€æŸ¥æ˜¯å¦é‡æ–°æ‰¾åˆ°
            frame = self.vision.capture_frame()
            target = self.vision.find_target(frame)
            
            if target is not None:
                print("âœ“ Target re-acquired!")
                self.vision.lost_frame_count = 0
                self.motion.reset_pid()
                return STATE_TRACK
            
            await asyncio.sleep(0.5)
        
        print("âœ— Search timeout. Returning to BLE search...")
        return STATE_BLE_SEARCH
    
    async def run(self):
        """ä¸»å¾ªç¯"""
        # åˆå§‹åŒ–
        if not await self.initialize():
            return
        
        # çŠ¶æ€æœºå¾ªç¯
        self.state = STATE_BLE_SEARCH
        
        try:
            while self.running:
                self.previous_state = self.state
                
                # çŠ¶æ€åˆ†å‘
                if self.state == STATE_BLE_SEARCH:
                    self.state = await self.state_ble_search()
                
                elif self.state == STATE_ALIGN:
                    self.state = await self.state_align()
                
                elif self.state == STATE_CAPTURE:
                    self.state = await self.state_capture()
                
                elif self.state == STATE_TRACK:
                    self.state = await self.state_track()
                    await asyncio.sleep(CONTROL_DT)  # æ§åˆ¶å¾ªç¯é¢‘ç‡
                
                elif self.state == STATE_LOST:
                    self.state = await self.state_lost()
                
                elif self.state == STATE_STOP:
                    print("\n[STOP] Robot stopped.")
                    self.motion.stop()
                    break
                
        except KeyboardInterrupt:
            print("\n\n  Keyboard interrupt detected!")
        
        finally:
            # æ¸…ç†
            print("\n" + "="*50)
            print("Shutting down...")
            print("="*50)
            self.motion.stop()
            self.stm32.disconnect()
            self.vision.cleanup()
            if SAVE_DEBUG_IMAGES:
                cv2.destroyAllWindows()
            print("âœ“ Shutdown complete.")


# ========== ç¨‹åºå…¥å£ ==========
if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘   Visual Tracking Robot System         â•‘
    â•‘   Press Ctrl+C to stop                 â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    tracker = RobotTracker()
    asyncio.run(tracker.run())